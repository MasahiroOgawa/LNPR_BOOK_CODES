{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "from dp_policy_agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DpPolicyAgent2(DpPolicyAgent): \n",
    "    def __init__(self, *args, **kwargs): \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.history = []\n",
    "        \n",
    "    def init_policy(self, index_nums):\n",
    "        tmp = np.zeros(np.r_[index_nums,2])\n",
    "        for line in open(\"/Users/ueda/GIT/LoPR_BOOK/reinforcement_learning_results/sarsa0_policy3500000.txt\", \"r\"):\n",
    "            d = line.split()\n",
    "            tmp[int(d[0]), int(d[1]), int(d[2])] = [float(d[3]), float(d[4])]\n",
    "            \n",
    "        return tmp\n",
    "    \n",
    "    def policy(self, pose, goal=None): \n",
    "        a = self.policy_data[self.to_index(pose, self.pose_min, self.index_nums, self.widths)]\n",
    "        self.history.append(a)\n",
    "        \n",
    "        ##左右に回転が続いたら前進というヒューリスティックを加える##\n",
    "        if len(self.history) < 2: return a\n",
    "        if self.history[-1][0] + self.history[-2][0] == 0.0 and self.history[-1][1] + self.history[-2][1] == 0.0: #過去二回の速度、角速度の和がゼロ\n",
    "            return (1.0, 0.0)\n",
    "        \n",
    "        return a\n",
    "    \n",
    "    def draw(self, ax, elems):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial():  ###dppolicyagentrun\n",
    "    time_interval = 0.1\n",
    "    world = PuddleWorld(300, time_interval, debug=False) \n",
    "\n",
    "    ## 地図を生成して3つランドマークを追加 ##\n",
    "    m = Map()\n",
    "    for ln in [(-4,2), (2,-3), (4,4), (-4,-4)]: m.append_landmark(Landmark(*ln))\n",
    "    world.append(m)   \n",
    "\n",
    "    ##ゴールの追加##\n",
    "    goal = Goal(-3,-3)  #goalを変数に\n",
    "    world.append(goal)\n",
    "    \n",
    "    ##水たまりの追加##\n",
    "    world.append(Puddle((-2, 0), (0, 2), 0.1)) \n",
    "    world.append(Puddle((-0.5, -2), (2.5, 1), 0.1)) \n",
    "\n",
    "    ##4台のロボットを動かしてみる##   ##dppolicyagentrun\n",
    "    init_poses = []\n",
    "    for p in [[-1,3,np.pi], [1, 3, np.pi], [3, 3, np.pi], [3, 1, np.pi], [3, -1, np.pi]]:\n",
    "        init_pose = np.array(p).T\n",
    "    \n",
    "        kf = KalmanFilter(m, init_pose)\n",
    "        a = DpPolicyAgent2(time_interval, kf, goal)\n",
    "        r = Robot(init_pose, sensor=Camera(m, distance_bias_rate_stddev=0, direction_bias_stddev=0), \n",
    "              agent=a, color=\"red\", bias_rate_stds=(0,0))\n",
    "\n",
    "        world.append(r)\n",
    "        \n",
    "    world.draw()\n",
    "    \n",
    "trial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
